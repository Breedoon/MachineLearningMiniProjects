{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "animal-description",
   "metadata": {},
   "source": [
    "# Image Classification with **_Deep Learning_**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-impression",
   "metadata": {},
   "source": [
    "To build a model classifying clothes into male and female we will be using the same dataset of [male](https://course-resources.minerva.kgi.edu/uploaded_files/mke/nA93zn/male-clothing.zip) and [female](https://course-resources.minerva.kgi.edu/uploaded_files/mke/VL14ar/female-clothing.zip) clothing, this time using Support Vector machines and a pre-trained deep neural network. \n",
    "\n",
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-reunion",
   "metadata": {},
   "source": [
    "Since VGG16 (the pre-trained model) was built on 224x224 images, we would resize our images to that resolution. We can compress them further and use some form of dimensionality reduction like PCA for the SVMs as well, but it would be a more interesting task to use as much data as we have to achieve an absolute maximum performance these models can achieve.\n",
    "\n",
    "The metric we can use to measure the models' performance is accuracy, since the dataset is well-balanced (because for an unbalanced dataset accuracy might be misleading), and it also treats true negatives equally as true positives (unlike f-1 score), and false positives equally as false negatives (unlike precision or recall), and we don't have any reason to prefer performance on male or female clothes over the other. Also, accuracy is pretty straightforward to interpret (while keeping in mind that in an equally split dataset a random classifier would achieve ~0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "olive-aside",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg16\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "level-dating",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Directory containing the Man's Clothing and Woman's Clothing subfolders\n",
    "fashion_dir = r\"C:\\Users\\breedoon\\Downloads\\Fashion Dataset\"\n",
    "target_im_size = (224, 224)  # default vgg16 input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considered-spice",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "img_gen = ImageDataGenerator(rescale=1 / 255).flow_from_directory(fashion_dir,\n",
    "                                                                  target_size=target_im_size,\n",
    "                                                                  class_mode='binary',\n",
    "                                                                  batch_size=1)\n",
    "x, y = tuple(zip(*[img_gen[i] for i in range(len(img_gen))]))  # cannot do just *img_gen because will run infinitely\n",
    "x, y = np.array(x)[:, 0, ...], np.array(y)[:, 0]\n",
    "\n",
    "x_flat = x.reshape(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "demanding-recruitment",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, x_flat_train, x_flat_test, y_train, y_test = train_test_split(x, x_flat, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-completion",
   "metadata": {},
   "source": [
    "## SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-saint",
   "metadata": {},
   "source": [
    "We will train an SVM wit three different kernels: a linear one, a polynomial one, and an RBF one. For each of them we would cross-validate to find the best value of C (controlling the error margin), and then calculate the test accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "opposed-completion",
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear\n",
      "Test Accuracy: 0.6284095427435387 \n",
      "\n",
      "Kernel: poly\n",
      "Test Accuracy: 0.6821471172962226 \n",
      "\n",
      "Kernel: rbf\n",
      "Test Accuracy: 0.7218489065606361 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernels = [\n",
    "    dict(kernel='linear'),\n",
    "    dict(kernel='poly', degree=2),\n",
    "    dict(kernel='rbf'),\n",
    "]\n",
    "for kernel_params in kernels:\n",
    "    grid_params = dict(C=[0.001, 0.1, 1, 10, 1000], **({k: [v] for k, v in kernel_params.items()}))\n",
    "\n",
    "    grid_search = GridSearchCV(SVC(), param_grid=grid_params)\n",
    "    grid_search.fit(x_flat_train, y_train)\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    model_svm = SVC(**best_params, C=10)\n",
    "    model_svm.fit(x_flat_train, y_train)\n",
    "\n",
    "    y_pred = model_svm.predict(x_flat_test)\n",
    "    print('Kernel:', kernel_params['kernel'])\n",
    "    print('Test Accuracy:', accuracy_score(y_test, y_pred), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-jersey",
   "metadata": {},
   "source": [
    "## Deep Learning Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-spirit",
   "metadata": {},
   "source": [
    "First, we would load the VGG16 model without the top layers and perform transfer learning by putting a single trainable layer with a sigmoid activation function (since we're doing binary classification) which would serve as the output of the model. Additionally, we would need to use a flatten layer to reshape the 224x224x3 input into 151,875-size output. Then, to prevent overfitting, we can put a dropout layer between the flatten and the sigmoid layers with varying dropout rates, which would serve as a regularization technique by occasionally dropping out some of the 151,875 connections while training, so that the model does not unreasonably learn to rely on only a few portion of them. We will use binary crossentropy as our loss function simply because we're doing binary classification, and there doesn't seem to be a better-suited loss function for that purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "included-position",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_raw = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(*target_im_size, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scenic-storage",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_dnn_model(dropout_rate=0.0):\n",
    "    flatten_layer = Flatten()\n",
    "    dropout_layer = Dropout(rate=dropout_rate)\n",
    "    output_layer = Dense(1, activation='sigmoid', name='clothes_output')\n",
    "\n",
    "    raw_input = model_raw.input\n",
    "    new_output = output_layer(dropout_layer(flatten_layer(model_raw.output)))\n",
    "\n",
    "    model = Model(raw_input, new_output)\n",
    "\n",
    "    # Freeze native VGG layers to not bother retraining them\n",
    "    for layer in model.layers[:len(model_raw.layers)]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-cotton",
   "metadata": {},
   "source": [
    "Then, we would perform cross-validation to find the optimal dropout rate and the number of epochs to train the model for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reverse-feeding",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'dropout_rate': 0.5, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "grid_params = dict(dropout_rate=[0.1, 0.3, 0.5, 0.7, 0.9], epochs=[5, 10, 20])\n",
    "\n",
    "model = KerasClassifier(build_fn=get_dnn_model)\n",
    "grid_search = GridSearchCV(model, param_grid=grid_params, cv=3)\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "print('Best params:', best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "systematic-collector",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 616/2009 [==========>...................] - ETA: 58s - loss: 1.7388 - accuracy: 0.5900"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 100000 exceeded with 100126 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_dnn_model(dropout_rate=best_params['dropout_rate'])\n",
    "model.fit(x_train, y_train, batch_size=1, epochs=best_params['epochs'], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "martial-caribbean",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9925335988053758\n",
      "Test Accuracy: 0.8500497017892644\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy:', accuracy_score(y_train, model.predict(x_train).round()))\n",
    "print('Test Accuracy:', accuracy_score(y_test, model.predict(x_test).round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-asbestos",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-citizen",
   "metadata": {},
   "source": [
    "So, using an unreduced dataset with extensive cross-validation, the neural network was able to achieve an astounding 85% accuracy on the training data while the SVM lagged behind with only 72%, which, compared to liner regression's maximum 68% does not seem like a huge improvement. This all comes at a cost of about equal grid-search time for both models (~4 hours). The time could've been brought down by reducing the dimensionality of the data, but since the goal was to achieve an absolute maximum, this might have resulted in lower performance of both models.\n",
    "\n",
    "Given that, the DNN seems to be the superior technique to classify images, which shouldn't come as a surprise given it was trained in the first place for that purpose, and also contains far more (sometimes deliberately placed) parameters, compared to a more general-purpose SVM which was trained on the spot. On the other hand, a liner regression took considerably less time to be trained and achieved a comparable level of accuracy as SVM (68% vs 72%), which might be the consequence of the data (a set of images) not being well suited for either of the two techniques, with only properly configured DNN managing to handle it well. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
