{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "little-central",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Topic Modeling with **_Latent Dirchlet Allocation_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "young-cricket",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from stop_words import get_stop_words\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "documented-translator",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('1998-0.txt', encoding='utf-8') as f:  # Also sprach Zaratustra\n",
    "    full_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accepting-macro",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NON_ALPHABETICAL = re.compile('[\\W_^0-9]+', re.UNICODE)\n",
    "words = [' '.join([NON_ALPHABETICAL.sub('', word).lower() for word in paragraph.split()\n",
    "                   if word.strip().lower() not in get_stop_words('english')])\n",
    "         for paragraph in full_text.split('\\n\\n')]  # double new line separates paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stupid-insertion",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# max_df to cut off words that are too frequent like names or unidentified stop-words\n",
    "# min_df to remove words that are too rare such as typos or meta data\n",
    "cv = CountVectorizer(stop_words='english', max_df=0.1, min_df=0.001)\n",
    "\n",
    "x = cv.fit_transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "signal-genetics",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy on actual clusters\n",
    "true_clusters = np.loadtxt(\"questionnaire_answers.csv\", delimiter=\",\")\n",
    "\n",
    "(people.argmax(axis=1) == true_clusters).sum() / n_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "composed-gothic",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(max_iter=100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=10, max_iter=100)\n",
    "lda.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "committed-throat",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "day, thee, verily, thyself, death, soul, life, new, unto, thy\n",
      "\n",
      "Topic 2:\n",
      "shall, time, voice, woman, love, man, came, said, unto, spake\n",
      "\n",
      "Topic 3:\n",
      "great, long, laughter, tell, higher, men, shall, chapter, brethren, ye\n",
      "\n",
      "Topic 4:\n",
      "higher, says, life, discourse, works, gutenbergtm, nietzsches, work, project, nietzsche\n",
      "\n",
      "Topic 5:\n",
      "doth, thy, hath, small, heaven, earth, great, body, soul, spirit\n",
      "\n",
      "Topic 6:\n",
      "doth, thing, wanteth, world, great, things, evil, hath, good, man\n",
      "\n",
      "Topic 7:\n",
      "lie, spirit, good, little, wise, like, god, thee, man, old\n",
      "\n",
      "Topic 8:\n",
      "thyself, said, shadow, wilt, friend, like, hast, art, thy, thee\n",
      "\n",
      "Topic 9:\n",
      "live, verily, shall, higher, men, let, virtue, ones, love, ye\n",
      "\n",
      "Topic 10:\n",
      "yea, sit, learned, wisdom, old, come, good, ah, long, hath\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(lda.components_):\n",
    "    print(f'Topic {i + 1}:')\n",
    "    print(', '.join([cv.get_feature_names()[i] for i in topic.argsort()[-10:]]) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
